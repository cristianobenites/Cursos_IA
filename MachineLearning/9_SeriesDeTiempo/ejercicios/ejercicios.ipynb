{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/MachineLearning/9_SeriesDeTiempo/ejercicios/ejercicios.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>\n",
    "<div align=\"center\"> Recordá abrir en una nueva pestaña </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Series de Tiempo\n",
    "\n",
    "## Dataset: Flujo Vehicular por Unidades de Peaje AUSA\n",
    "\n",
    "**Podés descargar el dataset [aquí](https://unket.s3.sa-east-1.amazonaws.com/data/flujo-vehicular-2017_2021_illia.csv). Deberás descargar -  al menos para comenzar - el archivo \"flujo-vehicular-2017_2021_illia.csv\". Los datasets originales los podés encontrar [aquí](https://data.buenosaires.gob.ar/dataset/flujo-vehicular-por-unidades-de-peaje-ausa). Nosotros ya hicimos un preprocesamiento para que sea más sencillo trabajar con los dataset durante la clase. Si querés ver cómo es ese preprocesamiento, podés mirar el notebook \"PreproDatasets.ipynb\".**\n",
    "\n",
    "En este notebook te dejamos unas celdas para que puedas comenzar a trabajar con este dataset. También te dejamos algunas propuestas para que explores. ¡No te preocupes si no llegas a probarlas todas durante la clase!\n",
    "\n",
    "Las secciones del notebook son las siguientes:\n",
    "\n",
    "1. Exploración de datos\n",
    "1. Objetivos del análisis\n",
    "1. Componentes de la serie\n",
    "1. Predicción a Futuro\n",
    "1. Para pensar, investigar y, opcionalmente, implementar\n",
    "\n",
    "#### Bibliografía recomendada\n",
    "\n",
    "El análisis que haremos es muy similar al que se encuentra en el [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) de Jake VanderPlas sobre el dataset de pasos de bicicletas en el Puente Fremont de Seattle, EEUU. Recomendamos las secciones \"Working with Time Series\" e \"In Depth: Linear Regression\". También, recomendamos chusmear el libro \"Interpretable Machine Learning\", de Christoph Molnar, en particular la sección \"5.1 Linear Regression\", donde pueden encontrar otro ejemplo similar.\n",
    "\n",
    "\n",
    "## 1. Exploración de datos\n",
    "\n",
    "Dedícale un buen tiempo a hacer un Análisis Exploratorio de Datos. Elige preguntas que creas que puedas responder con este dataset. Por ejemplo, ¿Cuáles son los días y horarios de mayor tráfico? También, puedes estudiar autocorrelaciones, resampleos, etc. ¿La serie posee valores atípicos? Si es así, interpreta, si es necesario con información auxiliar. \n",
    "\n",
    "Nosotros te dejamos unas celdas para comenzar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://unket.s3.sa-east-1.amazonaws.com/data/flujo-vehicular-2017_2021_illia.csv', \n",
    "                   parse_dates = [1])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinamos la columna `fecha` y `hora_inicio`,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['fecha'] = pd.to_datetime(data.fecha) + pd.to_timedelta(data.hora_inicio, unit = 'h')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar el análisis, vamos a sumar la `cantidad_pasos` a lo largo de todas las formas de pago y tipos de vehículo. Solamente vamos a separar por `sentido`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reducida = data.groupby(['fecha', 'sentido']).cantidad_pasos.sum()\n",
    "data_reducida = data_reducida.reset_index()\n",
    "data_reducida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llevamos el DataFrame a una forma un poquito más cómoda, pivoteando la tabla en la columna `sentido`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reducida = data_reducida.pivot_table(index = 'fecha',columns=['sentido'], values='cantidad_pasos')\n",
    "data_reducida.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reducida.reset_index(inplace = True)\n",
    "data_reducida.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reducida = data_reducida.rename_axis(None, axis=1) # Para sacarle nombre `sentido` al indice\n",
    "data_reducida.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos si hay valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reducida.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y que no falten fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reducida.fecha.diff().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, hay muy pocos valores y fechas faltantes. En general, está bueno agregar las fechas que falten y, a veces, imputar valores, pero por hoy vamos a obviarlo.\n",
    "\n",
    "Sumamos una columna `Total`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reducida['Total'] = data_reducida['Centro'] + data_reducida['Provincia']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y graficamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reducida.plot(x = 'fecha', y = ['Centro', 'Provincia'], alpha = 0.5, figsize = (18,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La visualización está un poco saturada. Sin embargo, se llegan a ver algunas características sobresalientes. ¿Cuáles son?\n",
    "\n",
    "Veamos más de cerca algunos días individuales. Antes de correr la serie, anticipa lo que esperas ver, en particular en cada *sentido* del tránsito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia = datetime.datetime(2017,3,5,0,0) # un domingo. ¿qué pasa si sumás un día?\n",
    "\n",
    "data_reducida.plot(x = 'fecha', y = ['Centro', 'Provincia'], figsize = (18,6))\n",
    "plt.xlim(dia,dia + datetime.timedelta(days = 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 1:** Podemos resamplear para obtener una visualización un poco más amigable. Para ello, utiliza la función `resample` de Pandas para obtener la cantidad de pasos **diarios**. Y grafica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diario = COMPLETAR.COMPLETAR.sum()\n",
    "diario.reset_index(inplace = True)\n",
    "diario.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diario.plot(COMPLETAR, figsize = (18,6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 2:** Utilizando la función `groupby` de Pandas, obtén el tráfico promedio **por hora**. Te puede ser útil el comando `data_reducida.fecha.dt.time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_por_hora = COMPLETAR.COMPLETAR(COMPLETAR).mean()\n",
    "data_por_hora.reset_index(inplace = True)\n",
    "data_por_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_por_hora.plot(style=[':', '--', '-']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 3:** De la misma forma, obtén el tráfico por día. Pista: `data_reducida.fecha.dt.dayofweek`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_por_dia = COMPLETAR\n",
    "data_por_dia.index = ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo']\n",
    "data_por_dia.plot(style=[':', '--', '-']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio 4:** Combina ambos análisis para obtener el gráfico del tráfico por hora para los días de la semana y los días de fin de semana. Te dejamos algunas pistas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_de_semana = np.where(data_reducida.fecha.dt.dayofweek < 5, 'Semana', 'Fin de semana')\n",
    "fin_de_semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_por_hora = data_reducida.groupby([COMPLETAR, COMPLETAR]).mean()\n",
    "data_por_hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks_por_hora = 4 * 60 * 60 * np.arange(6)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "data_por_hora.loc['Semana'].plot(ax=ax[0], title='Semana',\n",
    "                           xticks=ticks_por_hora, style=[':', '--', '-'])\n",
    "data_por_hora.loc['Fin de semana'].plot(ax=ax[1], title='Fin de semana',\n",
    "                           xticks=ticks_por_hora, style=[':', '--', '-']);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Se te ocurre algo más que te gustaría explorar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAZLO AQUI SI ES EL CASO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Objetivos del análisis\n",
    "\n",
    "Piensa algunos posibles objetivos de este análisis. ¿Qué partes interesadas pueden haber en el análisis de un dataset de estas características? Piensa también en aplicaciones similares pero de otros ámbitos.\n",
    "\n",
    "COMPLETAR\n",
    "\n",
    "## 3. Componentes de la serie\n",
    "\n",
    "Utilizando Prophet, obtén las componentes de la serie para el Total de pasos. Observa qué ocurre si utilizas los datos con resolución horaria y los datos con resolución diaria. ¿Qué componente se agrega? También, explora a mano distintos argumentos del modelo.\n",
    "\n",
    "Para resolver esta sección, puedes utilizar celdas de los materiales asincrónicos. No te preocupes por ahora en separar los datos en *train* y *test*.\n",
    "\n",
    "**Nota:** En Colab la librería se llama *fbprophet*, mientras que localmente *prophet*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from prophet import Prophet\n",
    "# from prophet.diagnostics import cross_validation, performance_metrics\n",
    "# from prophet.plot import plot_plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a_descomponer = COMPLETAR # data_reducida o diario\n",
    "data_a_descomponer.rename(COMPLETAR, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciamos modelo\n",
    "m = COMPLETAR\n",
    "\n",
    "# fiteamos el modelo\n",
    "m.COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para graficar, hacemos predict\n",
    "forecast_train = m.COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "2dpayoLEjZEy",
    "outputId": "1317b837-89c0-4ae8-a736-7141c7669e3a"
   },
   "outputs": [],
   "source": [
    "# componentes del forecast\n",
    "m.plot_components(forecast_train,uncertainty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Predicción a Futuro\n",
    "\n",
    "Utilizando Prophet, obtén un modelo para predecir el tráfico Total para el último trimestre del 2019. Empieza por el tráfico diario, luego si tienes tiempo ve a una resolución mayor (horaria). ¿Contra qué modelos de referencia compararías? Si bien estaría bueno que los implementes, aunque sea coméntalos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_a_predecir = COMPLETAR # data_reducida o diario\n",
    "data_a_predecir.rename(COMPLETAR, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "a31j3ywQjZEw",
    "outputId": "06044304-7eab-458b-87c3-c44beebbcc9f"
   },
   "outputs": [],
   "source": [
    "mask_train = data_a_predecir.ds < datetime.datetime(2019,10,1) #conveniente para despues\n",
    "train = COMPLETAR[COMPLETAR].copy()\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "w8Rz6MBEJm7w",
    "outputId": "0f6ca614-347c-40bc-a737-79e21125efb0"
   },
   "outputs": [],
   "source": [
    "train.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_test = (data_a_predecir.ds >= datetime.datetime(2019,10,1)) & \\\n",
    "            (data_a_predecir.ds < datetime.datetime(2020,1,1))\n",
    "\n",
    "fechas_a_predecir = COMPLETAR[COMPLETAR].ds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgFyYRsejZEx"
   },
   "outputs": [],
   "source": [
    "# generamos un dataset futuro para hacer la prediccion\n",
    "futuro = pd.DataFrame({'ds': fechas_a_predecir, 'y': np.nan})\n",
    "futuro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "2dpayoLEjZEy",
    "outputId": "1317b837-89c0-4ae8-a736-7141c7669e3a"
   },
   "outputs": [],
   "source": [
    "# instanciamos modelo\n",
    "m = COMPLETAR\n",
    "\n",
    "# fiteamos el modelo en TRAIN\n",
    "m.COMPLETAR\n",
    "\n",
    "# predecimos en futuro\n",
    "forecast = m.COMPLETAR\n",
    "\n",
    "# para graficar, hacemos predict tambien en train\n",
    "forecast_train = m.COMPLETAR\n",
    "\n",
    "# #unimos los dos DFs para visualizar las dos partes, train-prediccion\n",
    "forecast_final = pd.concat([forecast_train, forecast])\n",
    "\n",
    "# #plot componentes del forecast\n",
    "m.plot_components(forecast_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "g3zODTKtjZE2",
    "outputId": "f6dd578b-8143-4c37-b8e4-06dd336921c2"
   },
   "outputs": [],
   "source": [
    "m.plot(forecast_final)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparemos contra los datos originales, separando en *train* y *test*. Observa atentamente la *forma* de las predicciones. ¿Notas algo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,6))\n",
    "plt.plot(forecast_final.ds, forecast_final.yhat, alpha = 0.75, \n",
    "         label = 'Predicho', color = 'blue')\n",
    "plt.fill_between(forecast_final.ds, forecast_final.yhat_lower, forecast_final.yhat_upper,\n",
    "                 alpha = 0.1, color = 'blue' )\n",
    "\n",
    "\n",
    "plt.plot(data_a_predecir[mask_train].ds, data_a_predecir[mask_train].y, alpha = 0.75, label = 'Train')\n",
    "plt.plot(data_a_predecir[mask_test].ds, data_a_predecir[mask_test].y, alpha = 0.75, label = 'Test')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(datetime.datetime(2019,8,1),datetime.datetime(2020,1,1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el diario del lunes sabemos que el modelo no va a andar muy bien en el 2020. De todas formas, predice sobre 2020 y observa las predicciones. ¿Hay algo que un pronosticador podría haber hecho en 2019 para anticiparse?¿Siempre se puede predecir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_2020 = (COMPLETAR) & \\\n",
    "            (COMPLETAR)\n",
    "\n",
    "fechas_a_predecir = data_a_predecir[COMPLETAR].ds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgFyYRsejZEx"
   },
   "outputs": [],
   "source": [
    "# generamos un dataset futuro para hacer la prediccion\n",
    "futuro = pd.DataFrame({'ds': fechas_a_predecir, 'y': np.nan})\n",
    "futuro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "2dpayoLEjZEy",
    "outputId": "1317b837-89c0-4ae8-a736-7141c7669e3a"
   },
   "outputs": [],
   "source": [
    "# predecimos en futuro\n",
    "forecast = m.COMPLETAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (18,6))\n",
    "plt.plot(forecast.ds, forecast.yhat, alpha = 0.75, \n",
    "         label = 'Predicho', color = 'blue')\n",
    "plt.fill_between(forecast.ds, forecast.yhat_lower, forecast.yhat_upper,\n",
    "                 alpha = 0.1, color = 'blue' )\n",
    "\n",
    "plt.plot(data_a_predecir[mask_2020].ds, data_a_predecir[mask_2020].y, alpha = 0.75, label = '2020')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Para pensar, investigar y, opcionalmente, implementar\n",
    "\n",
    "¿Cómo incorporarías la información sobre tipo de vehículo, forma de pago, sentido, día de la semana, etc.? En lo que respecta a las predicciones, ¿esperas que mejoren o empeoren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
